# 多种组件的对比


zookeeper
leader读写、follower、observer读
“过半写成功”策略
由于有leader节点，所以存在脑裂问题

elasticsearch
由于有master节点，所以存在脑裂问题


脑裂是什么？
- 比如有两个机房，每个机房3台机器，其中有一个leader。当机房之间网络断了之后，机房内的zk还是可以通信，所以每个机房都会选举出一个leader。于是发生了脑裂

会有什么问题？
- 当网络回复的时候，两个集群都对外提供了服务，数据该怎么合并，数据冲突怎么解决。

zookeeper是怎么解决脑裂的？ [脑裂是什么？Zookeeper是如何解决的？](https://blog.csdn.net/l18848956739/article/details/97398463) [Zookeeper的脑裂问题及解决方案](https://www.jianshu.com/p/234a26ab1693)
- zk采用了快速领导者选举算法（FastLeaderElection），要求得到半数节点以上的投票才能成为Leader，
- 而脑裂之后，最多只有一个集群中的节点数能超过半数，这就保证leader的唯一性。
- 那最终结果就是脑裂之后的多个集群中要么有一个leader要么没有leader。

使用zookeeper来实现业务服务的选主HA，这种应用场景下会出现脑裂吗？可以怎样解决？ [](https://www.cnblogs.com/kevingrace/p/12433503.html)
- 可能会发生
    - 业务服务Leader 和 Zk集群的心跳超时，Zk通知其他Follower，于是立马会有一个Follower成为新的Leader；但是原Leader可能只是网络中断，并没有宕机。
    - 如果”ZK引起的Leader切换“先于”原Leader资源释放“，那么，原Leader在未释放完资源的情况下还是能对外提供服务，导致一部分Client连接的是老Leader，另一部分Client连接的是新Leader。
    - 如果此时发生对同一数据的更新，则会导致数据不一致。
- 解决
    - follower想要切换成leader时，先经历一个超时时间，以便原Leader自己先下线，然后才有新的Master产生。

zookeeper是怎么保证事务的顺序性的？
- zookeeper的leader为其它每个server都准备了一个FIFO的队列，保证顺序性

初始选举模拟个流程？
- 3台机器S1,S2,S3
- S1启动并广播提案(1,0)以投票给自己
- S2启动并广播提案(2,0)以投票给自己，同时S1收到S2的提案，发现S2的serverId=2，大于自己，于是接受S2的提议。
- 至此，S2已有2个节点的投票，因此成为leader。

宕机选举模拟个流程？
- 假设S2宕机，S1广播提案(1, 98)以投票给自己，S3广播提案(3, 99)以投票给自己，然后S1就会发现S3比自己更适合当Leader，于是接受S3的提案，S3成为leader。

崩溃恢复？
- follower崩溃，没影响
- leader崩溃，分情况
    - leader提交了提案，但没有follower收到提案。那么原leader恢复后成为follower之后要比较并丢弃这个提案
    - leader提交了提案，且至少有一个follower收到了提案。那么通过zxid比较，只有拥有最新数据的节点才有可能成为leader

数据模型
- 层次结构的命名空间，跟文件目录很像

zookeeper的应用
- 选主 [使用Zookeeper实现选举](https://www.jianshu.com/p/87556c35d932) [使用curator实现选举](https://www.jianshu.com/p/93c00dc622df)
    - 非公平模式
        - 先创建一个持久节点
        - 多台机器同时创建临时节点，创建成功成为master，失败则注册Watcher进行监听
        - master宕机后，会回调Watcher，于是客户端再次选主
    - 公平模式
        - 先创建一个持久节点
        - 多台机器同时创建临时顺序节点，节点数字最小的成为master，失败则对前一个节点注册Watcher进行监听
        - master宕机后，会回调Watcher，于是下一个客户端成为主
- 分布式锁
    - 非公平锁，同选主一样的流程
    - 公平独占锁，创建临时节点，如果当前节点是最小节点则获取到锁，否则监听前一个节点
    - 公平共享锁，创建临时节点，如果当前节点是最小节点则获取到锁，否则读请求监听比自己小的最后一个写请求节点，写请求监听比自己小的最后一个节点、
- 命名服务
    - 利用全路径来命名，因为全路径是唯一的
- 集群管理 和 注册中心
    - 创建一个持久的父节点，然后在这个父节点下为每台机器创建临时节点，通过监控父节点就能得知集群中机器的状态。同理，注册中心也是一样的，每台机器只需要把自己的ip等信息上传。

## RocketMQ

消息顺序：
- 发布/订阅 topic，topic下有多个队列（对应一个消费组里边的多个消费者），以提供高性能
- 这样子就会存在消息顺序的问题，所以要将一类的消息做hash取模，保证这一类消息只进一个队列，那么就能保证消息的顺序了

数据重复：
- 消费方做幂等，QOS等级保证至少有一次

事务消息：
- 三阶段，略

数据不丢失：
- producer
    - 失败自动重试，最终失败，代码做幂等
        - 同步刷盘、异步刷盘：是否从 virtual memory 中 flush 到磁盘上
        - 同步复制、异步复制 和 Dledger：是否同步到slave才算写入成功，Dledger半数成功支持选主
- broker部署，分片 + 主从
    - 分片，横向扩展
    - 主 能写能读，从 只能读，保障数据一致性
    - 两者加起来，保障数据可靠性
- consumer
    - consume offset，本地持久化，上报broker，失败重试，重启重试
    
为什么不使用ZK，而是要单独开发NameServer？为什么NameServer设计成去中心化多实例的？设计成这样有什么问题，然后Rocket怎么解决的？
- RocketMQ中仅仅需要一个高可用的，数据最终一致的，元数据管理中心，而ZK强调强一致性。另外，对于一个框架而言，能移除别的依赖是一件好事儿，kafka也准备这么做。
- Broker需要和所有NameServer通信，Producer和Consumer只需要跟一个NameServer通信，NameServer之间互不通信，所以的确存在数据不一致的情况。之所以这么设计，是考虑高可用，只要有一台NameServer在线，集群就可用。
- 会有数据不一致的情况，通过 服务端定时剔除节点、客户端定时拉取更新路由 和 客户端负载均衡重试 解决的。
    
Terry推荐：[RocketMQ 主题扩分片后遇到的坑](https://blog.csdn.net/prestigeding/article/details/100588188)

Terry推荐：[Rocketmq为什么选择自己开发NameServer，而不是选择类似于ZK这样的开源组件？](https://www.jianshu.com/p/456f9759bb97)

[RocketMQ消息消费一：消息拉取](https://blog.csdn.net/yankunhaha/article/details/99078998)

[【RocketMq实战第四篇】-不同类型消费者（DefaultMQPushConsumer&DefaultMQPullConsumer）](https://blog.csdn.net/weixin_38003389/article/details/86658396)

## Kafka

模型上？
- 跟RocketMQ简直一模一样
- Producer
- Broker
    - Partition（对应rocket的queue）
    - 也支持 水平扩展partition以提高性能
    - 也支持 指定partition，或指定key来对partition取余，或自动生成counter来对partition取余(counter是递增1的)
- Consumer，ConsumerGroup
- 但是kafka还支持
    - 批量发送，
    
kafka重平衡和rocketmq之间？
- kafka重平衡指一个消费组中，一个消费者进入或离开后，触发了消费者与partition的绑定关系的调整
- rocket也有这个问题

kafka和rocket在管理broker集群上有什么不同？
- rocket是靠nameserver来对broker集群进行管理，没有依赖zk
- 而kafka是有一个broker会成为协调者，然后由它进行集群管理。kafka依赖了zk，是靠zk实现的Controller选主。
- 然后Partition选主就没有依赖zk，而是靠Controller来实现的。[Kafka Partition Leader选主机制](https://blog.csdn.net/qq_27384769/article/details/80115392)
    
kafka的partition与消费模型
- partition之间消息是无序的，只有partition内才是有序，需要指定partition或key的值来将同一类消息路由到同一个partition，这样能做到局部有序
- 消息只会过期，不会删除，多个consumerGroup是依靠offset来定位消费到了哪里

为什么kafka效率高？
- 未满一个批次或轮循时间未到，加入到批次末尾，然后以批次发送，减少网络io
- 消息都会被追加到 Partition 文件的尾部，顺序写磁盘效率比随机写内存还要高，能保证高吞吐率
- 底层采用segment方式存储，包含 稀疏索引存储 和 数据文件存储，总是成对出现。通过一次二分、一次offset查找就能定位数据

kafka的pull模型
- push模型无法适应消费者的消费速率，可能造成拒绝额服务
- push模型的话，则可以根据consumer的消费能力调整消费速度
- 相比较rocketmq，rocket也是采用 长pull 的方式获取数据

kafka如何保证可靠性 [Kafka 是如何保证数据可靠性和一致性](https://www.cnblogs.com/PigeonNoir/articles/11043542.html)
- 发送消息ack，可以指定0、1 和 all，可靠性依次递增（发送就成功，发送并写入分区文件然后返回确认，发送并同步到指定副本个数然后返回确认）
- topic分区副本保证已存储数据不丢失
- Leader选举，拥有最新数据的follower才能参与选举，跟zk一样的思路
- 综上，需要配置producer、topic、和broker级别的参数配置。

## RabbitMQ

[RabbitMQ几个常用面试题](https://www.cnblogs.com/woadmin/p/10537174.html)

如何保证RabbitMQ消息的可靠传输？
- 生产者可靠性
    - 开启confirm模式，消息队列返回ack表示成功，nack表示失败需要重试
- 消息队列可靠性
    - 开启队列的持久化模式，或者设置消息的deliveryMode=2表示需要持久化
    - 开启镜像集群模式，有多个副本，保证消息不丢 [RabbitMQ 的4种集群架构](https://www.jianshu.com/p/b7cc32b94d2a)
- 消费者可靠性
    - todo
## 消息协议

- JMS
    - 点到点，基于队列
    - 发布/订阅，基于topic
    - ActiveMQ基于JMS实现
- AMQP
    - 五种消息模型：direct、fanout、topic、headers、system
    - RabbitMQ基于AMQP实现



## MySQL

master/slave 架构
- 同步刷盘、异步刷盘
- 同步复制、异步复制、**半同步复制**
- io线程拉取binlog到relaylog中，sql线程执行relaylog中的指令，异步执行存在延迟，可开启半同步复制，保证至少有一个slave写入成功才算整体写入成功

## Eureka

Eureka和Zookeeper比较
- Eureka保证的是AP，
- Zookeeper保证的是CP，快速领导者选举算法，要么一个Leader，要么没有Leader，但对外提供服务的集群数据是一致的。

### 分布式事务简单比较
- 2PC (2 phase commit)
    - 分为 协调者、参与者
    - 过程分为两阶段
        - 第一阶段，协调者发送prepare，各个参与者执行本地事务但不提交，返回结果
        - 第二阶段，协调者，根据返回结果是否全成功来发送commit或rollback，各个参与者提交或回滚
    - 问题
        - 协调者单点故障，系统不可用
        - 协调者发送了prepare后故障，其他参与者的资源无法释放
        - 协调者发送了一部分commit后故障，数据不一致了，总而言之，问题多
- 3PC
    - 相比2PC，加入了超时机制，能减少阻塞时间，但是数据一致性仍然无法解决
    
## Redis

主从复制？
- todo

Sentinel中选主？
- 先经历两次淘汰，主要淘汰那些下线、断线、超时的从节点
- 在剩余的节点中，选择 复制偏移量(replication offset)最大的从节点，或者带有最小运行ID的从节点