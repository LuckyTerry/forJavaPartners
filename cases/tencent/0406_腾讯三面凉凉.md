# 三面凉凉 by terry

对前面2位同学，有什么印象深刻的？
- 前面2位同学都有讲到Zookeeper，关于它的基本概念和脑裂情况的分析，我都没能很好答上来。所以下来后也有专项地去了解。
- zk集群的脑裂分析，略；zk用于选主时的脑裂分析，略。

如何指定Zookeeper集群中一台机器作为主机？
- 没找到答案！！？

你的优势是什么？
- 细心、负责（带团队接近2年）
- 学习能力强（两次转岗，基于对自己学习能力的信任）

spring boot 的启动流程？比如这个Listener，在启动过程中是如何通知各个Listener的呢？
- 构造函数
    - 初始化Initilize、Listener、主类Class
- run方法启动
    - 初始化RunListeners，对外提供事件发送接口，对内通知各个Listener，就是个manager的作用
    - 初始化Environment
    - 初始化上下文Context并刷新，以启动spring容器和servlet容器
    - 调用自定义的 CommandLineRunner、ApplicationRunner，执行自定义逻辑的调用
io模型介绍下？io多路复用也是基于事件驱动的，跟你说的“事件驱动IO”又有什么区别呢？
- 异步IO、同步非阻塞IO、同步非阻塞IO多路复用、信号驱动IO
- 口误了，事件驱动IO应该是信号驱动IO。另外，IO多路复用的确是基于事件的，连接、可读、可写事件，由selector阻塞select事件，然后派发事件给相应的事件处理器。

拓扑图，SLB到Nginx到底是怎么走的？到底是slb到nginx还是slb到k8s？
- todo

elasticsearch？
- 只是了解，并没有掌握细节。

你的工作职责是什么？
- todo
- 架构选型、组件封装、团队组建、业务开发、方案评审、任务分解、项目推动

熔断是怎么做的？除了时间窗口还有别的方式实现熔断吗？
- todo
- 我知道可以基于滑动窗口统计失败率。还有哪些方式？没找到答案！！
    - 默认1个滑动窗口包含10个桶(bucket)，每个桶时间宽度1秒。底层采用LongAddr、LongMaxUpdater来实现 [Hystrix浅入浅出：（二）断路器和滑动窗口](https://blog.csdn.net/manzhizhen/article/details/80296655)
- 使用的是hystrix熔断，基于滑动窗口实现。单位时间内，错误率（返回错误、超时等都视为错误）达到阈值便打开断路器，以保护服务消费方不被拖死。
- hystrix和sentinel的比较
    - 隔离上，Sentinel的信号量熔断支持对慢调用自动进行降级，性能好又能降级。
    - 熔断降级策略，sentinel和hystrix都支持错误率的熔断降级，但是sentinel还支持基于平均时间的熔断降级，功能更强。

限流是怎么做的？Gateway redis漏桶怎么实现的？基于ip限流有什么问题？
- todo
- 网关使用redis的令牌桶实现 [request_rate_limiter.lua](https://github.com/spring-cloud/spring-cloud-gateway/blob/master/spring-cloud-gateway-core/src/main/resources/META-INF/scripts/request_rate_limiter.lua)
    - 基于redis的key限流，key可以是用户维度、URI维度等等，我们使用的是用户IP
    - 大体逻辑是根据key找到上一次的token剩余数量和刷新时间，根据“添加令牌的速率”和“上一个刷新时间到当前时间的时间差”计算出增量的令牌，与原有的令牌的和作为可用令牌数。
    - 同时，定义从空桶填满的时间为t，那么以2倍t作为过期时间，去设置 本次token剩余数量和刷新时间。
- 服务间调用使用线程池隔离来限流，来不及处理的请求会入队列，队列已满则会拒绝请求。
- 基于ip限流是局部上的，同时应该定义基于URI或基于全局的限流策略，搭配使用，避免集群整体的流量过高。

为什么要采用redis的snowflake方案？单机的snowflake用到redis上怪怪的？靠k8S不能提供机器id吗？
- todo
- 不是纯正的snowflake，我们并没有使用机房号、机器号，而是对于同一个时间戳，由redis来保证自增序列不重复。
- 原生的snowflake使用了 时间戳 + 机房号 + 机器号 + 自增序列 完成。
- 我们则是使用了“redis生成时间戳和共享自增序列，本地执行bit位移计算ID”来完成。对于同一个时间戳，由 redis lua 脚本中的逻辑来保证所有客户端操作的是同一个自增序列。
    - 方案的坏处是降低了TPS，单个的业务每毫秒只能有1024个可用ID
    - 好处是严格单调递增，实现简单，可快速上线。另外，项目还暂时不存在1秒高于千万TPS的场景。